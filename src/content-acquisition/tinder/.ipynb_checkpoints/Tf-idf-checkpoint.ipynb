{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import yaml\n",
    "import os\n",
    "from spacy.vocab import Vocab\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pallavi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open('../../../config/tinder.yaml', 'r') as ymlfile:\n",
    "        cfg = yaml.load(ymlfile)\n",
    "path = cfg['output_folder']+cfg['city']+'/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')]\n",
    "def import_bios(path):\n",
    "    with open(path) as fp:\n",
    "        temp = json.load(fp)\n",
    "        ids = [i['_id'] for i in temp['results'] if i['bio']]\n",
    "        bio = [i['bio'] for i in temp['results'] if i['bio']]\n",
    "        return ids,bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids,bios = import_bios(path+json_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chipotle and fitness just about sums me up\\n\\nIG: hannahh______',\n",
       " 'I like big boats and I cannot lie',\n",
       " 'Insta:ava_homsey',\n",
       " 'Future hockey mom\\nvenmo- alyssa-Stcroix\\nSnap alyssamareigh',\n",
       " '“Could be cooler” -VOGUE  \\n“If only she could spell” -The Gordian \\n“She gave herself five stars.” -Roger Ebert']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_sw_dict(bios):\n",
    "    nlp = spacy.load('en')\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for i, doc in enumerate(bios):\n",
    "        doc = nlp(doc)\n",
    "        bios[i] = \" \".join([token.lemma_ for token in doc if str(token) in words and str(token) not in stop_words])\n",
    "        return bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-15a702a1e6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlemma_sw_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-f619ac11741c>\u001b[0m in \u001b[0;36mlemma_sw_dict\u001b[0;34m(bios)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "lemma_sw_dict(bios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and fitness just about sum up',\n",
       " 'like big boat and can not lie',\n",
       " '',\n",
       " 'future hockey snap',\n",
       " 'be cool if only could spell give five star']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12)\t0.5773502691896258\n",
      "  (0, 6)\t0.5773502691896258\n",
      "  (0, 3)\t0.5773502691896258\n",
      "  (1, 7)\t0.5\n",
      "  (1, 1)\t0.5\n",
      "  (1, 0)\t0.5\n",
      "  (1, 8)\t0.5\n",
      "  (3, 9)\t0.5773502691896258\n",
      "  (3, 5)\t0.5773502691896258\n",
      "  (3, 4)\t0.5773502691896258\n",
      "  (4, 11)\t0.5773502691896258\n",
      "  (4, 10)\t0.5773502691896258\n",
      "  (4, 2)\t0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', smooth_idf= True)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big', 'boat', 'cool', 'fitness', 'future', 'hockey', 'just', 'lie', 'like', 'snap', 'spell', 'star', 'sum']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and fitness just about sum up : 0.13323467750529827\n",
      "like big boat and can not lie : 0.15384615384615385\n",
      " : 0.0\n",
      "future hockey snap : 0.13323467750529827\n",
      "be cool if only could spell give five star : 0.13323467750529827\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(vec,corpus):\n",
    "    print(j,\":\",sum(i)/len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7320508075688776, 2.0, 0.0, 1.7320508075688776, 1.7320508075688776]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
